From 92c48742bcde3d078592eb0f32e37f494a5bcfab Mon Sep 17 00:00:00 2001
From: shiwanghua <2804324275@qq.com>
Date: Sun, 4 Jan 2026 09:17:01 +0000
Subject: [PATCH] add train config data and sh

---
 batch_dpo.sh                                  | 110 +++++++++++-----
 data/dataset_info.json                        |  32 ++++-
 examples/merge_lora/qwen2.5_lora_32b.yaml     |  13 ++
 .../merge_lora/qwen3_lora_coder_oumi.yaml     |  13 ++
 examples/merge_lora/qwen3_lora_dpo.yaml       |   4 +-
 ...aml => qwen3_lora_llama-factory-orpo.yaml} |   6 +-
 examples/merge_lora/qwen3_lora_orpo.yaml      |   4 +-
 .../train_lora/qwen3_930b3_lora_dpo_orpo.yaml | 108 ++++++++++++++++
 examples/train_lora/qwen3_lora_dpo.yaml       |  90 -------------
 examples/train_lora/qwen3_qlora_dpo1.yaml     | 116 +++++++++++++++++
 examples/train_lora/qwen3_qlora_orpo19.yaml   | 118 ++++++++++++++++++
 examples/train_lora/qwen3_qlora_orpo20.yaml   | 114 +++++++++++++++++
 examples/train_lora/qwen3_qlora_orpo21.yaml   | 114 +++++++++++++++++
 examples/train_lora/qwen3_qlora_orpo22.yaml   | 114 +++++++++++++++++
 examples/train_lora/qwen3_qlora_orpo23.yaml   | 114 +++++++++++++++++
 examples/train_lora/qwen3_qlora_orpo25.yaml   | 117 +++++++++++++++++
 examples/train_lora/qwen3_qlora_orpo26.yaml   | 117 +++++++++++++++++
 .../model/model_utils/quantization.py         |   1 +
 src/llamafactory/train/dpo/trainer.py         |   1 +
 19 files changed, 1171 insertions(+), 135 deletions(-)
 create mode 100644 examples/merge_lora/qwen2.5_lora_32b.yaml
 create mode 100644 examples/merge_lora/qwen3_lora_coder_oumi.yaml
 rename examples/merge_lora/{qwen3_lora_dpo9.yaml => qwen3_lora_llama-factory-orpo.yaml} (75%)
 create mode 100644 examples/train_lora/qwen3_930b3_lora_dpo_orpo.yaml
 delete mode 100644 examples/train_lora/qwen3_lora_dpo.yaml
 create mode 100644 examples/train_lora/qwen3_qlora_dpo1.yaml
 create mode 100644 examples/train_lora/qwen3_qlora_orpo19.yaml
 create mode 100644 examples/train_lora/qwen3_qlora_orpo20.yaml
 create mode 100644 examples/train_lora/qwen3_qlora_orpo21.yaml
 create mode 100644 examples/train_lora/qwen3_qlora_orpo22.yaml
 create mode 100644 examples/train_lora/qwen3_qlora_orpo23.yaml
 create mode 100644 examples/train_lora/qwen3_qlora_orpo25.yaml
 create mode 100644 examples/train_lora/qwen3_qlora_orpo26.yaml

diff --git a/batch_dpo.sh b/batch_dpo.sh
index 51b8ebb2..e2f92978 100755
--- a/batch_dpo.sh
+++ b/batch_dpo.sh
@@ -1,43 +1,89 @@
 
 
 
-DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
- --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-sft_model13 \
- --dataset  'c_cpp_completion_dpo_train_data_20250609_1600' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
- --lora_rank 16  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
- --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter8 --use_dora False \
- --pref_loss orpo --pref_beta 0.1  --overwrite_cache --overwrite_output_dir --cutoff_len 8194 --enable_liger_kernel  \
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-sft_model13 \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 16  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter8 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.1  --overwrite_cache --overwrite_output_dir --cutoff_len 8194 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 1000  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end    --learning_rate 5e-6 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  \
+#  --plot_loss  --bf16 --optim adamw_torch >> log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo-8_20250718.log
+
+# llamafactory-cli export examples/merge_lora/qwen3_lora_dpo.yaml >> log/merge_250716.log
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/train_models/selekt_stage1_instruction_train13/checkpoint-123 \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 16  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter9 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.1  --overwrite_cache --overwrite_output_dir --cutoff_len 8194 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 1000  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end    --learning_rate 5e-6 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  \
+#  --plot_loss  --bf16 --optim adamw_torch >> log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo-9_20250718.log
+
+
+# OOM
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,2 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 64  --lora_alpha 16 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-12 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.05  --overwrite_cache --overwrite_output_dir --cutoff_len 6144 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 1000  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end  --learning_rate 8e-5 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim rmsprop \
+#  > log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamaf-orpo-12_20250823.log
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,2 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 64  --lora_alpha 16 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-12 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.05  --overwrite_cache --overwrite_output_dir --cutoff_len 3072 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 1000  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end  --learning_rate 8e-5 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim rmsprop \
+#   > log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamaf-orpo-12_20250823.log
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,2 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 64  --lora_alpha 16 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-13 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.05  --overwrite_cache --overwrite_output_dir --cutoff_len 4096 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 1000  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end  --learning_rate 8e-5 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim rmsprop \
+#   > log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamaf-orpo-13_20250823.log
+
+DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,2 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+ --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B \
+ --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+ --lora_rank 128  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+ --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-14 --use_dora False \
+ --pref_loss orpo --pref_beta 0.05  --overwrite_cache --overwrite_output_dir --cutoff_len 8192 --enable_liger_kernel  \
  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
- --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 1000  --eval_steps 500  --eval_strategy steps  \
- --load_best_model_at_end    --learning_rate 5e-6 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  \
- --plot_loss  --bf16 --optim adamw_torch >> log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo-8_20250718.log
+ --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500 \
+ --learning_rate 8e-5 --loraplus_lr_ratio 12.0 --num_train_epochs 12.0  --ddp_timeout 180000000  --plot_loss  --bf16 --optim rmsprop \
+ --quantization_bit 4 --quantization_method bnb --double_quantization true \
+  > log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamaf-orpo-14_20250823.log
+  #  --val_size 0.0  --eval_steps 500  --eval_strategy steps  --load_best_model_at_end
 
-llamafactory-cli export examples/merge_lora/qwen3_lora_dpo.yaml >> log/merge_250716.log
+llamafactory-cli export examples/merge_lora/qwen3_lora_llama-factory-orpo.yaml >> log/merge_250823.log
 
+CUDA_VISIBLE_DEVICES=0  llamafactory-cli train examples/train_lora/qwen3_lora_dpo_orpo.yaml > log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamaf-orpo-14_20250823.log 
 
-DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
- --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/train_models/selekt_stage1_instruction_train13/checkpoint-123 \
- --dataset  'c_cpp_completion_dpo_train_data_20250609_1600' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
- --lora_rank 16  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
- --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter9 --use_dora False \
- --pref_loss orpo --pref_beta 0.1  --overwrite_cache --overwrite_output_dir --cutoff_len 8194 --enable_liger_kernel  \
- --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
- --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 1000  --eval_steps 500  --eval_strategy steps  \
- --load_best_model_at_end    --learning_rate 5e-6 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  \
- --plot_loss  --bf16 --optim adamw_torch >> log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo-9_20250718.log
-
-
-
-llamafactory-cli export examples/merge_lora/qwen3_lora_dpo9.yaml >> log/merge_250716.log
-
-
-
-conda activate swh-vllm
+# conda activate swh-vllm
 
-cd ../AssessModel
+# cd ../AssessModel
 
-python llm_pre_assess.py >> data/R1_0528_Qwen3_8B-lora-dpo_20250702/cpp_train8_4000_250719.cpp
+# python llm_pre_assess.py >> data/R1_0528_Qwen3_8B-lora-dpo_20250702/cpp_train8_4000_250719.cpp
 
-python llm_pre_assess_250719.py >> data/R1_0528_Qwen3_8B-lora-dpo_20250702/cpp_train9_4000_250719.cpp
+# python llm_pre_assess_250719.py >> data/R1_0528_Qwen3_8B-lora-dpo_20250702/cpp_train9_4000_250719.cpp
 
-python cal_rates.py
\ No newline at end of file
+# python cal_rates.py
\ No newline at end of file
diff --git a/data/dataset_info.json b/data/dataset_info.json
index f6930305..fe1eb779 100644
--- a/data/dataset_info.json
+++ b/data/dataset_info.json
@@ -31,8 +31,8 @@
       "response": "output"
     }
   },
-  "c_cpp_completion_dpo_train_data_20250609_1300": {
-    "file_name": "/home/ubisec/swh/codes/AssessModel/data/train_data/c_cpp_completion_dpo_train_data_20250609_1300.json",
+  "c_cpp_completion_llamafactory-orpo_train_data_20250609_1300": {
+    "file_name": "/home/ubisec/swh/codes/AssessModel/data/train_data/llamafactory-orpo/c_cpp_completion_llamafactory-orpo_train_data_20250609_1300.json",
     "ranking": true,
     "columns": {
       "prompt": "instruction",
@@ -41,8 +41,8 @@
       "rejected": "rejected"
     }
   },
-  "c_cpp_completion_dpo_train_data_20250609_1600": {
-    "file_name": "/home/ubisec/swh/codes/AssessModel/data/train_data/c_cpp_completion_dpo_train_data_20250609_1600.json",
+  "c_cpp_completion_llamafactory-orpo_train_data_20250609_1600": {
+    "file_name": "/home/ubisec/swh/codes/AssessModel/data/train_data/llamafactory-orpo/c_cpp_completion_llamafactory-orpo_train_data_20250609_1600.json",
     "ranking": true,
     "columns": {
       "prompt": "instruction",
@@ -51,8 +51,28 @@
       "rejected": "rejected"
     }
   },
-  "c_cpp_completion_dpo_train_data_20250609_1600_random800": {
-    "file_name": "/home/ubisec/swh/codes/AssessModel/data/train_data/random800/cpp_completion_dpo_800_train_dataset_20250609.json",
+  "c_cpp_completion_llamafactory-orpo_train_data_20250609_1600_random800": {
+    "file_name": "/home/ubisec/swh/codes/AssessModel/data/train_data/random800/cpp_completion_llamafactory-orpo_800_train_dataset_20250609.json",
+    "ranking": true,
+    "columns": {
+      "prompt": "instruction",
+      "query": "input",
+      "chosen": "chosen",
+      "rejected": "rejected"
+    }
+  },
+  "c_cpp_completion_llamafactory-orpo_train_data_20250609_1600_random800_add_reason": {
+    "file_name": "/home/ubisec/swh/codes/AssessModel/data/train_data/random800/add_reason_250905_cpp_completion_llamafactory_orpo_800_train_dataset_20250609.json",
+    "ranking": true,
+    "columns": {
+      "prompt": "instruction",
+      "query": "input",
+      "chosen": "chosen",
+      "rejected": "rejected"
+    }
+  },
+  "c_cpp_completion_20250609-qa-orpo_1373_train_data_20250918": {
+    "file_name": "/home/ubisec/swh/codes/AssessModel/data/train_data/cz_good_bad_qa_1373/cpp_completion_20250609-qa-llamafactory_orpo_1373_train_dataset_20250918.json",
     "ranking": true,
     "columns": {
       "prompt": "instruction",
diff --git a/examples/merge_lora/qwen2.5_lora_32b.yaml b/examples/merge_lora/qwen2.5_lora_32b.yaml
new file mode 100644
index 00000000..e404a42b
--- /dev/null
+++ b/examples/merge_lora/qwen2.5_lora_32b.yaml
@@ -0,0 +1,13 @@
+### Note: DO NOT use quantized model or quantization_bit when merging lora adapters
+
+### model
+model_name_or_path: /home/ubisec/cjr/models/mergekit/DTCoderAgent1116
+adapter_name_or_path: /home/ubisec/cjr/sft/qwen2.5_32b_sft_1211_output/checkpoint-1850
+template: qwen
+trust_remote_code: true
+
+### export
+export_dir: /home/ubisec/swh/train_models/qwen2.5_32b_sft_1211_cp1850
+export_size: 5
+export_device: cpu  # choices: [cpu, auto]
+export_legacy_format: false
diff --git a/examples/merge_lora/qwen3_lora_coder_oumi.yaml b/examples/merge_lora/qwen3_lora_coder_oumi.yaml
new file mode 100644
index 00000000..e48a4956
--- /dev/null
+++ b/examples/merge_lora/qwen3_lora_coder_oumi.yaml
@@ -0,0 +1,13 @@
+### Note: DO NOT use quantized model or quantization_bit when merging lora adapters
+
+### model
+model_name_or_path: /home/ubisec/cjr/models/Qwen/Qwen3-Coder-30B-A3B-Instruct
+adapter_name_or_path: /home/ubisec/cjr/models/Qwen/train_adapters/oumi-instruct-lora1-cp669-251121
+template: qwen3
+trust_remote_code: true
+
+### export
+export_dir: /home/ubisec/cjr/models/Qwen/trained_models/oumi-instruct-lora1-cp669-251121
+export_size: 5
+export_device: cpu  # choices: [cpu, auto]
+export_legacy_format: false
diff --git a/examples/merge_lora/qwen3_lora_dpo.yaml b/examples/merge_lora/qwen3_lora_dpo.yaml
index 2ef70dfc..03b1a948 100644
--- a/examples/merge_lora/qwen3_lora_dpo.yaml
+++ b/examples/merge_lora/qwen3_lora_dpo.yaml
@@ -2,12 +2,12 @@
 
 ### model
 model_name_or_path: /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B
-adapter_name_or_path: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter11/checkpoint-2000
+adapter_name_or_path: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamaf-dpo-orpo-adapter-25/checkpoint-4000
 template: qwen3
 trust_remote_code: true
 
 ### export
-export_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_model11_cp2000
+export_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamaf-orpo_model12_cp4000
 export_size: 5
 export_device: cpu  # choices: [cpu, auto]
 export_legacy_format: false
diff --git a/examples/merge_lora/qwen3_lora_dpo9.yaml b/examples/merge_lora/qwen3_lora_llama-factory-orpo.yaml
similarity index 75%
rename from examples/merge_lora/qwen3_lora_dpo9.yaml
rename to examples/merge_lora/qwen3_lora_llama-factory-orpo.yaml
index 8bd94b89..344d0524 100644
--- a/examples/merge_lora/qwen3_lora_dpo9.yaml
+++ b/examples/merge_lora/qwen3_lora_llama-factory-orpo.yaml
@@ -1,13 +1,13 @@
 ### Note: DO NOT use quantized model or quantization_bit when merging lora adapters
 
 ### model
-model_name_or_path: /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B
-adapter_name_or_path: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter9/checkpoint-4560
+model_name_or_path: /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B-2
+adapter_name_or_path: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-25
 template: qwen3
 trust_remote_code: true
 
 ### export
-export_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_model9_4560
+export_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo_model25-2
 export_size: 5
 export_device: cpu  # choices: [cpu, auto]
 export_legacy_format: false
diff --git a/examples/merge_lora/qwen3_lora_orpo.yaml b/examples/merge_lora/qwen3_lora_orpo.yaml
index 44c0a8c3..918afb17 100644
--- a/examples/merge_lora/qwen3_lora_orpo.yaml
+++ b/examples/merge_lora/qwen3_lora_orpo.yaml
@@ -2,12 +2,12 @@
 
 ### model
 model_name_or_path: /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B-2
-adapter_name_or_path: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-orpo_adapter23/checkpoint-7500
+adapter_name_or_path: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-orpo_adapter32
 template: qwen3
 trust_remote_code: true
 
 ### export
-export_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-orpo_model23_cp7500-2
+export_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-orpo_model32-2
 export_size: 5
 export_device: cpu  # choices: [cpu, auto]
 export_legacy_format: false
diff --git a/examples/train_lora/qwen3_930b3_lora_dpo_orpo.yaml b/examples/train_lora/qwen3_930b3_lora_dpo_orpo.yaml
new file mode 100644
index 00000000..821bef02
--- /dev/null
+++ b/examples/train_lora/qwen3_930b3_lora_dpo_orpo.yaml
@@ -0,0 +1,108 @@
+### model
+model_name_or_path: /home/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B
+trust_remote_code: true
+
+### method
+stage: dpo
+do_train: true
+finetuning_type: lora
+lora_rank: 128
+lora_alpha: 32
+lora_dropout: 0.05
+lora_target: all
+pref_beta: 0.05
+pref_loss: orpo  # choices: [sigmoid (dpo), orpo, simpo]
+use_dora: false
+use_rslora: true
+enable_liger_kernel: true
+flash_attn: fa2
+optim: rmsprop
+
+### dataset
+dataset: c_cpp_completion_dpo_train_data_20250609_1600_random800
+template: qwen3
+cutoff_len: 8192 # 2048
+max_samples: 20000
+overwrite_cache: true
+preprocessing_num_workers: 16
+dataloader_num_workers: 4
+
+### output
+output_dir: /home/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamaf-dpo-orpo-adapter-24
+logging_steps: 10
+save_steps: 500
+plot_loss: true
+overwrite_output_dir: true
+save_only_model: false
+report_to: none  # choices: [none, wandb, tensorboard, swanlab, mlflow]
+
+### train
+per_device_train_batch_size: 1
+gradient_accumulation_steps: 1 #8
+learning_rate: 8.0e-5 # 5.0e-6
+loraplus_lr_ratio: 12.0
+num_train_epochs: 6.0 # 训练总轮数
+lr_scheduler_type: cosine
+warmup_ratio: 0.1
+bf16: true
+ddp_timeout: 180000000
+resume_from_checkpoint: null
+
+### eval
+# eval_dataset: dpo_en_demo
+# val_size: 0.05
+# per_device_eval_batch_size: 1
+# eval_strategy: steps
+# eval_steps: 500
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path  \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 128  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir  --use_dora False --use_rslora True \
+#  --pref_loss orpo --pref_beta 0.05  --overwrite_cache --overwrite_output_dir --cutoff_len 8192 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end    --learning_rate 8e-5 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim rmsprop > log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamaf-dpo-orpo-24_20250822.log
+
+
+
+
+#  DISABLE_VERSION_CHECK=1 CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch --config_file ./config/fsdp_config.yaml ./LLaMA-Factory/src/train.py   \
+#  --stage dpo     --do_train  --model_name_or_path /home/ubisec/codeqwen/merged_kit_qwen_model_3/  \
+#  --dataset 'dpo_zh_data'     --dataset_dir  /home/ubisec/data/DPO_data     --template qwen     --finetuning_type lora  \
+#  --lora_rank 16     --lora_alpha 32     --lora_dropout 0.05     --lora_target all     --output_dir ./sft/dpo_qwen_all_1   \
+#  --use_dora True  --optim paged_adamw_8bit  --pref_loss orpo --pref_beta 0.1 \
+#  --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194   \
+#  --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16     --per_device_train_batch_size 1   \
+#  --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#  --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps    \
+#  --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0     --num_train_epochs 2.0     --val_size 0.05  \
+#  --ddp_timeout 180000000     --plot_loss     --bf16 
+
+# 第一版
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch  --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py --stage dpo  \
+#    --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B --dataset  'c_cpp_completion_dpo_train_data_20250609' \ 
+#    --dataset_dir  data/ --template qwen3  --finetuning_type lora  --lora_rank 32     --lora_alpha 32     --lora_dropout 0.05     --lora_target all   \
+#    --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter1 --use_dora False  --pref_loss orpo --pref_beta 0.1 \
+#    --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194    --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16  \
+#    --per_device_train_batch_size 1    --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#    --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps     --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0  \
+#    --num_train_epochs 2.0     --val_size 0.05   --ddp_timeout 180000000     --plot_loss     --bf16  --optim adamw_torch
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 128  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamaf-dpo-orpo-adapter-24 --use_dora False --use_rslora True \
+#  --pref_loss orpo --pref_beta 0.05  --overwrite_cache --overwrite_output_dir --cutoff_len 8192 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end    --learning_rate 8e-5 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim rmsprop > log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamaf-dpo-orpo-24_20250822.log
+
+
+
+ # --optim {adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,\
+ # adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,\
+ # paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,\
+ # galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}
\ No newline at end of file
diff --git a/examples/train_lora/qwen3_lora_dpo.yaml b/examples/train_lora/qwen3_lora_dpo.yaml
deleted file mode 100644
index d1e89111..00000000
--- a/examples/train_lora/qwen3_lora_dpo.yaml
+++ /dev/null
@@ -1,90 +0,0 @@
-### model
-model_name_or_path: /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B
-trust_remote_code: true
-
-### method
-stage: dpo
-do_train: true
-finetuning_type: lora
-lora_rank: 4
-lora_target: all
-pref_beta: 0.1
-pref_loss: sigmoid  # choices: [sigmoid (dpo), orpo, simpo]
-
-### dataset
-dataset: c_cpp_completion_dpo_train_data_20250609
-template: qwen3
-cutoff_len: 8192 # 2048
-max_samples: 2000
-overwrite_cache: true
-preprocessing_num_workers: 4 # 16
-dataloader_num_workers: 4
-
-### output
-output_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter1
-logging_steps: 10
-save_steps: 500
-plot_loss: true
-overwrite_output_dir: true
-save_only_model: false
-report_to: none  # choices: [none, wandb, tensorboard, swanlab, mlflow]
-
-### train
-per_device_train_batch_size: 1
-gradient_accumulation_steps: 8
-learning_rate: 5.0e-6
-num_train_epochs: 3.0
-lr_scheduler_type: cosine
-warmup_ratio: 0.1
-bf16: true
-ddp_timeout: 180000000
-resume_from_checkpoint: null
-
-### eval
-# eval_dataset: dpo_en_demo
-# val_size: 0.1
-# per_device_eval_batch_size: 1
-# eval_strategy: steps
-# eval_steps: 500
-
-
-
-#  DISABLE_VERSION_CHECK=1 CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch --config_file ./config/fsdp_config.yaml ./LLaMA-Factory/src/train.py   \
-#  --stage dpo     --do_train  --model_name_or_path /home/ubisec/codeqwen/merged_kit_qwen_model_3/  \
-#  --dataset 'dpo_zh_data'     --dataset_dir  /home/ubisec/data/DPO_data     --template qwen     --finetuning_type lora  \
-#  --lora_rank 16     --lora_alpha 32     --lora_dropout 0.05     --lora_target all     --output_dir ./sft/dpo_qwen_all_1   \
-#  --use_dora True  --optim paged_adamw_8bit  --pref_loss orpo --pref_beta 0.1 \
-#  --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194   \
-#  --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16     --per_device_train_batch_size 1   \
-#  --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
-#  --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps    \
-#  --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0     --num_train_epochs 2.0     --val_size 0.05  \
-#  --ddp_timeout 180000000     --plot_loss     --bf16 
-
-# 第一版
-DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch  --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py --stage dpo  \
-   --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B --dataset  'c_cpp_completion_dpo_train_data_20250609' \ 
-   --dataset_dir  data/ --template qwen3  --finetuning_type lora  --lora_rank 32     --lora_alpha 32     --lora_dropout 0.05     --lora_target all   \
-   --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter1 --use_dora False  --pref_loss orpo --pref_beta 0.1 \
-   --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194    --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16  \
-   --per_device_train_batch_size 1    --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
-   --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps     --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0  \
-   --num_train_epochs 2.0     --val_size 0.05   --ddp_timeout 180000000     --plot_loss     --bf16  --optim adamw_torch
-
-
-DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
- --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-orpo_model9 \
- --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
- --lora_rank 16  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
- --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter11 --use_dora False \
- --pref_loss orpo --pref_beta 0.1  --overwrite_cache --overwrite_output_dir --cutoff_len 8194 --enable_liger_kernel  \
- --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
- --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 1000  --eval_steps 500  --eval_strategy steps  \
- --load_best_model_at_end    --learning_rate 5e-6 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim adamw_torch
-
-
-
- --optim {adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,\
- adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,\
- paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,\
- galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}
\ No newline at end of file
diff --git a/examples/train_lora/qwen3_qlora_dpo1.yaml b/examples/train_lora/qwen3_qlora_dpo1.yaml
new file mode 100644
index 00000000..3244b121
--- /dev/null
+++ b/examples/train_lora/qwen3_qlora_dpo1.yaml
@@ -0,0 +1,116 @@
+### model
+model_name_or_path: /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B
+trust_remote_code: true
+
+### method
+stage: dpo
+do_train: true
+finetuning_type: lora
+lora_rank: 16
+lora_alpha: 16
+lora_dropout: 0.05
+lora_target: all
+pref_beta: 0.05
+pref_loss: sigmoid  # choices: [sigmoid (dpo), orpo, simpo]
+use_dora: false
+use_rslora: false
+enable_liger_kernel: true
+flash_attn: fa2
+optim: rmsprop # adamw_torch rmsprop
+# quantization_bit: 4
+# quantization_method: bnb  # choices: [bnb, gptq, smoothq
+# double_quantization: true
+
+### dataset
+dataset: c_cpp_completion_llamafactory-orpo_train_data_20250609_1600_random800
+template: qwen3
+cutoff_len: 8192 # 2048
+max_samples: 5000
+overwrite_cache: true
+preprocessing_num_workers: 16
+dataloader_num_workers: 4
+
+### output
+output_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-dpo-adapter-1
+logging_steps: 10
+save_steps: 500
+plot_loss: true
+overwrite_output_dir: true
+save_only_model: false
+report_to: none  # choices: [none, wandb, tensorboard, swanlab, mlflow]
+
+### train
+per_device_train_batch_size: 1
+gradient_accumulation_steps: 1 # 8
+learning_rate: 8.0e-5
+loraplus_lr_ratio: 12.0
+num_train_epochs: 6.0
+lr_scheduler_type: cosine
+warmup_ratio: 0.1
+bf16: true
+ddp_timeout: 180000000
+resume_from_checkpoint: null
+
+### eval
+# eval_dataset: dpo_en_demo
+# val_size: 0.1
+# per_device_eval_batch_size: 1
+# eval_strategy: steps
+# eval_steps: 500
+
+
+
+#  DISABLE_VERSION_CHECK=1 CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch --config_file ./config/fsdp_config.yaml ./LLaMA-Factory/src/train.py   \
+#  --stage dpo     --do_train  --model_name_or_path /home/ubisec/codeqwen/merged_kit_qwen_model_3/  \
+#  --dataset 'dpo_zh_data'     --dataset_dir  /home/ubisec/data/DPO_data     --template qwen     --finetuning_type lora  \
+#  --lora_rank 16     --lora_alpha 32     --lora_dropout 0.05     --lora_target all     --output_dir ./sft/dpo_qwen_all_1   \
+#  --use_dora True  --optim paged_adamw_8bit  --pref_loss orpo --pref_beta 0.1 \
+#  --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194   \
+#  --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16     --per_device_train_batch_size 1   \
+#  --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#  --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps    \
+#  --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0     --num_train_epochs 2.0     --val_size 0.05  \
+#  --ddp_timeout 180000000     --plot_loss     --bf16 
+
+# 第一版
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch  --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py --stage dpo  \
+#    --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B --dataset  'c_cpp_completion_dpo_train_data_20250609' \ 
+#    --dataset_dir  data/ --template qwen3  --finetuning_type lora  --lora_rank 32     --lora_alpha 32     --lora_dropout 0.05     --lora_target all   \
+#    --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter1 --use_dora False  --pref_loss orpo --pref_beta 0.1 \
+#    --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194    --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16  \
+#    --per_device_train_batch_size 1    --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#    --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps     --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0  \
+#    --num_train_epochs 2.0     --val_size 0.05   --ddp_timeout 180000000     --plot_loss     --bf16  --optim adamw_torch
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-orpo_model9 \
+#  --dataset  'c_cpp_completion_llamafactory-orpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 16  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo_adapter11 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.1  --overwrite_cache --overwrite_output_dir --cutoff_len 8194 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end    --learning_rate 5e-6 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim adamw_torch
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B \
+#  --dataset  'c_cpp_completion_llamafactory-orpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 16  --lora_alpha 16 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-dpo-adapter-1 --use_dora False --use_rslora False \
+#  --pref_loss sigmoid --pref_beta 0.05  --overwrite_cache --overwrite_output_dir --cutoff_len 8192 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500      \
+#  --learning_rate 8e-5 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --ddp_timeout 180000000  --plot_loss  --bf16 --optim rmsprop \
+# --quantization_bit 4 --quantization_method bnb --double_quantization True > log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-dpo1_20250903_2.log  
+# --val_size 0.05 --eval_strategy steps --eval_steps 500 --per_device_eval_batch_size 1  --load_best_model_at_end
+
+
+
+
+
+#  --optim {adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,\
+#  adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,\
+#  paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,\
+#  galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}
\ No newline at end of file
diff --git a/examples/train_lora/qwen3_qlora_orpo19.yaml b/examples/train_lora/qwen3_qlora_orpo19.yaml
new file mode 100644
index 00000000..e2e3282c
--- /dev/null
+++ b/examples/train_lora/qwen3_qlora_orpo19.yaml
@@ -0,0 +1,118 @@
+### model
+model_name_or_path: /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B
+trust_remote_code: true
+
+### method
+stage: dpo
+do_train: true
+finetuning_type: lora
+lora_rank: 64
+lora_alpha: 32
+lora_dropout: 0.05
+lora_target: all
+pref_beta: 0.05
+pref_loss: orpo  # choices: [sigmoid (dpo), orpo, simpo]
+use_dora: false
+use_rslora: false
+enable_liger_kernel: true
+flash_attn: fa2
+optim: adamw_torch
+quantization_bit: 4
+quantization_method: bnb  # choices: [bnb, gptq, smoothq
+double_quantization: true
+
+### dataset
+dataset: c_cpp_completion_llamafactory-orpo_train_data_20250609_1600_random800
+template: qwen3
+cutoff_len: 8192 # 2048
+max_samples: 5000
+overwrite_cache: true
+preprocessing_num_workers: 16
+dataloader_num_workers: 4
+
+### output
+output_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-19
+logging_steps: 10
+save_steps: 500
+plot_loss: true
+overwrite_output_dir: true
+save_only_model: false
+report_to: none  # choices: [none, wandb, tensorboard, swanlab, mlflow]
+
+### train
+per_device_train_batch_size: 1
+gradient_accumulation_steps: 1 # 8
+learning_rate: 8.0e-5 # 5.0e-6
+loraplus_lr_ratio: 12.0
+num_train_epochs: 6.0
+lr_scheduler_type: cosine
+warmup_ratio: 0.1
+bf16: true
+ddp_timeout: 180000000
+resume_from_checkpoint: null
+
+### eval
+# eval_dataset: dpo_en_demo
+# val_size: 0.1
+# per_device_eval_batch_size: 1
+# eval_strategy: steps
+# eval_steps: 500
+
+
+
+#  DISABLE_VERSION_CHECK=1 CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch --config_file ./config/fsdp_config.yaml ./LLaMA-Factory/src/train.py   \
+#  --stage dpo     --do_train  --model_name_or_path /home/ubisec/codeqwen/merged_kit_qwen_model_3/  \
+#  --dataset 'dpo_zh_data'     --dataset_dir  /home/ubisec/data/DPO_data     --template qwen     --finetuning_type lora  \
+#  --lora_rank 16     --lora_alpha 32     --lora_dropout 0.05     --lora_target all     --output_dir ./sft/dpo_qwen_all_1   \
+#  --use_dora True  --optim paged_adamw_8bit  --pref_loss orpo --pref_beta 0.1 \
+#  --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194   \
+#  --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16     --per_device_train_batch_size 1   \
+#  --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#  --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps    \
+#  --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0     --num_train_epochs 2.0     --val_size 0.05  \
+#  --ddp_timeout 180000000     --plot_loss     --bf16 
+
+# 第一版
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch  --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py --stage dpo  \
+#    --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B --dataset  'c_cpp_completion_dpo_train_data_20250609' \ 
+#    --dataset_dir  data/ --template qwen3  --finetuning_type lora  --lora_rank 32     --lora_alpha 32     --lora_dropout 0.05     --lora_target all   \
+#    --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter1 --use_dora False  --pref_loss orpo --pref_beta 0.1 \
+#    --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194    --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16  \
+#    --per_device_train_batch_size 1    --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#    --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps     --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0  \
+#    --num_train_epochs 2.0     --val_size 0.05   --ddp_timeout 180000000     --plot_loss     --bf16  --optim adamw_torch
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-orpo_model9 \
+#  --dataset  'c_cpp_completion_llamafactory-orpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 16  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo_adapter11 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.1  --overwrite_cache --overwrite_output_dir --cutoff_len 8194 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end    --learning_rate 5e-6 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim adamw_torch
+
+
+DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1,2 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+ --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/models/Qwen3-Coder-30B-A3B-Instruct \
+ --dataset  'c_cpp_completion_llamafactory-orpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+ --lora_rank 64  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+ --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-26 --use_dora False --use_rslora False \
+ --pref_loss orpo --pref_beta 0.05  --overwrite_cache --overwrite_output_dir --cutoff_len 8192 --enable_liger_kernel  \
+ --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 \
+ --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 10 \
+ --learning_rate 8e-5 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --ddp_timeout 180000000  --plot_loss  --bf16 --optim adamw_torch \
+ > log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-26_20250905.log
+#  --val_size 0.05  --load_best_model_at_end --per_device_eval_batch_size 1  --eval_steps 500  --eval_strategy steps 
+#  --quantization_bit 4 --quantization_method bnb --double_quantization True
+
+
+
+
+
+
+#  --optim {adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,\
+#  adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,\
+#  paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,\
+#  galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}
\ No newline at end of file
diff --git a/examples/train_lora/qwen3_qlora_orpo20.yaml b/examples/train_lora/qwen3_qlora_orpo20.yaml
new file mode 100644
index 00000000..7c4d10b4
--- /dev/null
+++ b/examples/train_lora/qwen3_qlora_orpo20.yaml
@@ -0,0 +1,114 @@
+### model
+model_name_or_path: /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B
+trust_remote_code: true
+
+### method
+stage: dpo
+do_train: true
+finetuning_type: lora
+lora_rank: 64
+lora_alpha: 32
+lora_dropout: 0.05
+lora_target: all
+pref_beta: 0.05
+pref_loss: orpo  # choices: [sigmoid (dpo), orpo, simpo]
+use_dora: false
+use_rslora: false
+enable_liger_kernel: true
+flash_attn: fa2
+optim: adamw_torch
+quantization_bit: 4
+quantization_method: bnb  # choices: [bnb, gptq, smoothq
+double_quantization: true
+
+### dataset
+dataset: c_cpp_completion_dpo_train_data_20250609_1600_random800
+template: qwen3
+cutoff_len: 8192 # 2048
+max_samples: 5000
+overwrite_cache: true
+preprocessing_num_workers: 16
+dataloader_num_workers: 4
+
+### output
+output_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-20
+logging_steps: 10
+save_steps: 500
+plot_loss: true
+overwrite_output_dir: true
+save_only_model: false
+report_to: none  # choices: [none, wandb, tensorboard, swanlab, mlflow]
+
+### train
+per_device_train_batch_size: 1
+gradient_accumulation_steps: 1 # 8
+learning_rate: 8.0e-5 # 5.0e-6
+loraplus_lr_ratio: 16.0
+num_train_epochs: 6.0
+lr_scheduler_type: cosine
+warmup_ratio: 0.1
+bf16: true
+ddp_timeout: 180000000
+resume_from_checkpoint: null
+
+### eval
+# eval_dataset: dpo_en_demo
+# val_size: 0.1
+# per_device_eval_batch_size: 1
+# eval_strategy: steps
+# eval_steps: 500
+
+
+
+#  DISABLE_VERSION_CHECK=1 CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch --config_file ./config/fsdp_config.yaml ./LLaMA-Factory/src/train.py   \
+#  --stage dpo     --do_train  --model_name_or_path /home/ubisec/codeqwen/merged_kit_qwen_model_3/  \
+#  --dataset 'dpo_zh_data'     --dataset_dir  /home/ubisec/data/DPO_data     --template qwen     --finetuning_type lora  \
+#  --lora_rank 16     --lora_alpha 32     --lora_dropout 0.05     --lora_target all     --output_dir ./sft/dpo_qwen_all_1   \
+#  --use_dora True  --optim paged_adamw_8bit  --pref_loss orpo --pref_beta 0.1 \
+#  --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194   \
+#  --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16     --per_device_train_batch_size 1   \
+#  --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#  --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps    \
+#  --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0     --num_train_epochs 2.0     --val_size 0.05  \
+#  --ddp_timeout 180000000     --plot_loss     --bf16 
+
+# 第一版
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch  --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py --stage dpo  \
+#    --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B --dataset  'c_cpp_completion_dpo_train_data_20250609' \ 
+#    --dataset_dir  data/ --template qwen3  --finetuning_type lora  --lora_rank 32     --lora_alpha 32     --lora_dropout 0.05     --lora_target all   \
+#    --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter1 --use_dora False  --pref_loss orpo --pref_beta 0.1 \
+#    --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194    --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16  \
+#    --per_device_train_batch_size 1    --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#    --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps     --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0  \
+#    --num_train_epochs 2.0     --val_size 0.05   --ddp_timeout 180000000     --plot_loss     --bf16  --optim adamw_torch
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-orpo_model9 \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 16  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo_adapter11 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.1  --overwrite_cache --overwrite_output_dir --cutoff_len 8194 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end    --learning_rate 5e-6 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim adamw_torch
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,2 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 128  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-13 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.05  --overwrite_cache --overwrite_output_dir --cutoff_len 8192 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end  --learning_rate 8e-5 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim rmsprop
+
+
+
+
+
+#  --optim {adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,\
+#  adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,\
+#  paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,\
+#  galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}
\ No newline at end of file
diff --git a/examples/train_lora/qwen3_qlora_orpo21.yaml b/examples/train_lora/qwen3_qlora_orpo21.yaml
new file mode 100644
index 00000000..3333c030
--- /dev/null
+++ b/examples/train_lora/qwen3_qlora_orpo21.yaml
@@ -0,0 +1,114 @@
+### model
+model_name_or_path: /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B
+trust_remote_code: true
+
+### method
+stage: dpo
+do_train: true
+finetuning_type: lora
+lora_rank: 64
+lora_alpha: 32
+lora_dropout: 0.05
+lora_target: all
+pref_beta: 0.05
+pref_loss: orpo  # choices: [sigmoid (dpo), orpo, simpo]
+use_dora: false
+use_rslora: true
+enable_liger_kernel: true
+flash_attn: fa2
+optim: adamw_torch
+quantization_bit: 4
+quantization_method: bnb  # choices: [bnb, gptq, smoothq
+double_quantization: true
+
+### dataset
+dataset: c_cpp_completion_dpo_train_data_20250609_1600_random800
+template: qwen3
+cutoff_len: 8192 # 2048
+max_samples: 5000
+overwrite_cache: true
+preprocessing_num_workers: 16
+dataloader_num_workers: 4
+
+### output
+output_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-21
+logging_steps: 10
+save_steps: 500
+plot_loss: true
+overwrite_output_dir: true
+save_only_model: false
+report_to: none  # choices: [none, wandb, tensorboard, swanlab, mlflow]
+
+### train
+per_device_train_batch_size: 1
+gradient_accumulation_steps: 1 # 8
+learning_rate: 8.0e-5 # 5.0e-6
+loraplus_lr_ratio: 12.0
+num_train_epochs: 6.0
+lr_scheduler_type: cosine
+warmup_ratio: 0.1
+bf16: true
+ddp_timeout: 180000000
+resume_from_checkpoint: null
+
+### eval
+# eval_dataset: dpo_en_demo
+# val_size: 0.1
+# per_device_eval_batch_size: 1
+# eval_strategy: steps
+# eval_steps: 500
+
+
+
+#  DISABLE_VERSION_CHECK=1 CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch --config_file ./config/fsdp_config.yaml ./LLaMA-Factory/src/train.py   \
+#  --stage dpo     --do_train  --model_name_or_path /home/ubisec/codeqwen/merged_kit_qwen_model_3/  \
+#  --dataset 'dpo_zh_data'     --dataset_dir  /home/ubisec/data/DPO_data     --template qwen     --finetuning_type lora  \
+#  --lora_rank 16     --lora_alpha 32     --lora_dropout 0.05     --lora_target all     --output_dir ./sft/dpo_qwen_all_1   \
+#  --use_dora True  --optim paged_adamw_8bit  --pref_loss orpo --pref_beta 0.1 \
+#  --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194   \
+#  --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16     --per_device_train_batch_size 1   \
+#  --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#  --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps    \
+#  --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0     --num_train_epochs 2.0     --val_size 0.05  \
+#  --ddp_timeout 180000000     --plot_loss     --bf16 
+
+# 第一版
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch  --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py --stage dpo  \
+#    --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B --dataset  'c_cpp_completion_dpo_train_data_20250609' \ 
+#    --dataset_dir  data/ --template qwen3  --finetuning_type lora  --lora_rank 32     --lora_alpha 32     --lora_dropout 0.05     --lora_target all   \
+#    --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter1 --use_dora False  --pref_loss orpo --pref_beta 0.1 \
+#    --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194    --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16  \
+#    --per_device_train_batch_size 1    --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#    --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps     --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0  \
+#    --num_train_epochs 2.0     --val_size 0.05   --ddp_timeout 180000000     --plot_loss     --bf16  --optim adamw_torch
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-orpo_model9 \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 16  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo_adapter11 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.1  --overwrite_cache --overwrite_output_dir --cutoff_len 8194 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end    --learning_rate 5e-6 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim adamw_torch
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,2 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 128  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-13 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.05  --overwrite_cache --overwrite_output_dir --cutoff_len 8192 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end  --learning_rate 8e-5 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim rmsprop
+
+
+
+
+
+#  --optim {adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,\
+#  adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,\
+#  paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,\
+#  galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}
\ No newline at end of file
diff --git a/examples/train_lora/qwen3_qlora_orpo22.yaml b/examples/train_lora/qwen3_qlora_orpo22.yaml
new file mode 100644
index 00000000..3d42bd60
--- /dev/null
+++ b/examples/train_lora/qwen3_qlora_orpo22.yaml
@@ -0,0 +1,114 @@
+### model
+model_name_or_path: /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B
+trust_remote_code: true
+
+### method
+stage: dpo
+do_train: true
+finetuning_type: lora
+lora_rank: 64
+lora_alpha: 32
+lora_dropout: 0.05
+lora_target: all
+pref_beta: 0.05
+pref_loss: orpo  # choices: [sigmoid (dpo), orpo, simpo]
+use_dora: false
+use_rslora: false
+enable_liger_kernel: true
+flash_attn: fa2
+optim: adamw_torch
+quantization_bit: 4
+quantization_method: bnb  # choices: [bnb, gptq, smoothq
+double_quantization: true
+
+### dataset
+dataset: c_cpp_completion_llamafactory-orpo_train_data_20250609_1600_random800
+template: qwen3
+cutoff_len: 8192 # 2048
+max_samples: 5000
+overwrite_cache: true
+preprocessing_num_workers: 16
+dataloader_num_workers: 4
+
+### output
+output_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-22
+logging_steps: 10
+save_steps: 500
+plot_loss: true
+overwrite_output_dir: true
+save_only_model: false
+report_to: none  # choices: [none, wandb, tensorboard, swanlab, mlflow]
+
+### train
+per_device_train_batch_size: 1
+gradient_accumulation_steps: 1 # 8
+learning_rate: 8.0e-5 # 5.0e-6
+loraplus_lr_ratio: 10.0
+num_train_epochs: 6.0
+lr_scheduler_type: cosine
+warmup_ratio: 0.1
+bf16: true
+ddp_timeout: 180000000
+resume_from_checkpoint: null
+
+### eval
+# eval_dataset: dpo_en_demo
+# val_size: 0.1
+# per_device_eval_batch_size: 1
+# eval_strategy: steps
+# eval_steps: 500
+
+
+
+#  DISABLE_VERSION_CHECK=1 CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch --config_file ./config/fsdp_config.yaml ./LLaMA-Factory/src/train.py   \
+#  --stage dpo     --do_train  --model_name_or_path /home/ubisec/codeqwen/merged_kit_qwen_model_3/  \
+#  --dataset 'dpo_zh_data'     --dataset_dir  /home/ubisec/data/DPO_data     --template qwen     --finetuning_type lora  \
+#  --lora_rank 16     --lora_alpha 32     --lora_dropout 0.05     --lora_target all     --output_dir ./sft/dpo_qwen_all_1   \
+#  --use_dora True  --optim paged_adamw_8bit  --pref_loss orpo --pref_beta 0.1 \
+#  --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194   \
+#  --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16     --per_device_train_batch_size 1   \
+#  --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#  --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps    \
+#  --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0     --num_train_epochs 2.0     --val_size 0.05  \
+#  --ddp_timeout 180000000     --plot_loss     --bf16 
+
+# 第一版
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch  --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py --stage dpo  \
+#    --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B --dataset  'c_cpp_completion_dpo_train_data_20250609' \ 
+#    --dataset_dir  data/ --template qwen3  --finetuning_type lora  --lora_rank 32     --lora_alpha 32     --lora_dropout 0.05     --lora_target all   \
+#    --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter1 --use_dora False  --pref_loss orpo --pref_beta 0.1 \
+#    --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194    --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16  \
+#    --per_device_train_batch_size 1    --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#    --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps     --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0  \
+#    --num_train_epochs 2.0     --val_size 0.05   --ddp_timeout 180000000     --plot_loss     --bf16  --optim adamw_torch
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-orpo_model9 \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 16  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo_adapter11 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.1  --overwrite_cache --overwrite_output_dir --cutoff_len 8194 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end    --learning_rate 5e-6 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim adamw_torch
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,2 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 128  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-13 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.05  --overwrite_cache --overwrite_output_dir --cutoff_len 8192 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end  --learning_rate 8e-5 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim rmsprop
+
+
+
+
+
+#  --optim {adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,\
+#  adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,\
+#  paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,\
+#  galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}
\ No newline at end of file
diff --git a/examples/train_lora/qwen3_qlora_orpo23.yaml b/examples/train_lora/qwen3_qlora_orpo23.yaml
new file mode 100644
index 00000000..da466941
--- /dev/null
+++ b/examples/train_lora/qwen3_qlora_orpo23.yaml
@@ -0,0 +1,114 @@
+### model
+model_name_or_path: /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B
+trust_remote_code: true
+
+### method
+stage: dpo
+do_train: true
+finetuning_type: lora
+lora_rank: 64
+lora_alpha: 32
+lora_dropout: 0.05
+lora_target: all
+pref_beta: 0.05
+pref_loss: orpo  # choices: [sigmoid (dpo), orpo, simpo]
+use_dora: false
+use_rslora: false
+enable_liger_kernel: true
+flash_attn: fa2
+optim: rmsprop
+quantization_bit: 4
+quantization_method: bnb  # choices: [bnb, gptq, smoothq
+double_quantization: true
+
+### dataset
+dataset: c_cpp_completion_llamafactory-orpo_train_data_20250609_1600_random800
+template: qwen3
+cutoff_len: 8192 # 2048
+max_samples: 5000
+overwrite_cache: true
+preprocessing_num_workers: 16
+dataloader_num_workers: 4
+
+### output
+output_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-23
+logging_steps: 10
+save_steps: 500
+plot_loss: true
+overwrite_output_dir: true
+save_only_model: false
+report_to: none  # choices: [none, wandb, tensorboard, swanlab, mlflow]
+
+### train
+per_device_train_batch_size: 1
+gradient_accumulation_steps: 1 # 8
+learning_rate: 8.0e-5 # 5.0e-6
+loraplus_lr_ratio: 12.0
+num_train_epochs: 6.0
+lr_scheduler_type: cosine
+warmup_ratio: 0.1
+bf16: true
+ddp_timeout: 180000000
+resume_from_checkpoint: null
+
+### eval
+# eval_dataset: dpo_en_demo
+# val_size: 0.1
+# per_device_eval_batch_size: 1
+# eval_strategy: steps
+# eval_steps: 500
+
+
+
+#  DISABLE_VERSION_CHECK=1 CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch --config_file ./config/fsdp_config.yaml ./LLaMA-Factory/src/train.py   \
+#  --stage dpo     --do_train  --model_name_or_path /home/ubisec/codeqwen/merged_kit_qwen_model_3/  \
+#  --dataset 'dpo_zh_data'     --dataset_dir  /home/ubisec/data/DPO_data     --template qwen     --finetuning_type lora  \
+#  --lora_rank 16     --lora_alpha 32     --lora_dropout 0.05     --lora_target all     --output_dir ./sft/dpo_qwen_all_1   \
+#  --use_dora True  --optim paged_adamw_8bit  --pref_loss orpo --pref_beta 0.1 \
+#  --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194   \
+#  --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16     --per_device_train_batch_size 1   \
+#  --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#  --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps    \
+#  --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0     --num_train_epochs 2.0     --val_size 0.05  \
+#  --ddp_timeout 180000000     --plot_loss     --bf16 
+
+# 第一版
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch  --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py --stage dpo  \
+#    --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B --dataset  'c_cpp_completion_dpo_train_data_20250609' \ 
+#    --dataset_dir  data/ --template qwen3  --finetuning_type lora  --lora_rank 32     --lora_alpha 32     --lora_dropout 0.05     --lora_target all   \
+#    --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter1 --use_dora False  --pref_loss orpo --pref_beta 0.1 \
+#    --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194    --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16  \
+#    --per_device_train_batch_size 1    --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#    --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps     --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0  \
+#    --num_train_epochs 2.0     --val_size 0.05   --ddp_timeout 180000000     --plot_loss     --bf16  --optim adamw_torch
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-orpo_model9 \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 16  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo_adapter11 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.1  --overwrite_cache --overwrite_output_dir --cutoff_len 8194 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end    --learning_rate 5e-6 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim adamw_torch
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,2 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B \
+#  --dataset  'c_cpp_completion_dpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 128  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-13 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.05  --overwrite_cache --overwrite_output_dir --cutoff_len 8192 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end  --learning_rate 8e-5 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim rmsprop
+
+
+
+
+
+#  --optim {adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,\
+#  adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,\
+#  paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,\
+#  galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}
\ No newline at end of file
diff --git a/examples/train_lora/qwen3_qlora_orpo25.yaml b/examples/train_lora/qwen3_qlora_orpo25.yaml
new file mode 100644
index 00000000..65d746e8
--- /dev/null
+++ b/examples/train_lora/qwen3_qlora_orpo25.yaml
@@ -0,0 +1,117 @@
+### model
+model_name_or_path: /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B-2
+trust_remote_code: true
+
+### method
+stage: dpo
+do_train: true
+finetuning_type: lora
+lora_rank: 64
+lora_alpha: 32
+lora_dropout: 0.05
+lora_target: all
+pref_beta: 0.05
+pref_loss: orpo  # choices: [sigmoid (dpo), orpo, simpo]
+use_dora: false
+use_rslora: false
+enable_liger_kernel: true
+flash_attn: fa2
+optim: adamw_torch
+quantization_bit: 4
+quantization_method: bnb  # choices: [bnb, gptq, smoothq
+double_quantization: true
+
+### dataset
+dataset: c_cpp_completion_llamafactory-orpo_train_data_20250609_1600_random800
+template: qwen3
+cutoff_len: 8192 # 2048
+max_samples: 5000
+overwrite_cache: true
+preprocessing_num_workers: 16
+dataloader_num_workers: 4
+
+### output
+output_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-25
+logging_steps: 10
+save_steps: 500
+plot_loss: true
+overwrite_output_dir: true
+save_only_model: false
+report_to: none  # choices: [none, wandb, tensorboard, swanlab, mlflow]
+
+### train
+per_device_train_batch_size: 1
+gradient_accumulation_steps: 1 # 8
+learning_rate: 8.0e-5 # 5.0e-6
+loraplus_lr_ratio: 12.0
+num_train_epochs: 6.0
+lr_scheduler_type: cosine
+warmup_ratio: 0.1
+bf16: true
+ddp_timeout: 180000000
+resume_from_checkpoint: null
+
+### eval
+# eval_dataset: dpo_en_demo
+# val_size: 0.1
+# per_device_eval_batch_size: 1
+# eval_strategy: steps
+# eval_steps: 500
+
+
+
+#  DISABLE_VERSION_CHECK=1 CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch --config_file ./config/fsdp_config.yaml ./LLaMA-Factory/src/train.py   \
+#  --stage dpo     --do_train  --model_name_or_path /home/ubisec/codeqwen/merged_kit_qwen_model_3/  \
+#  --dataset 'dpo_zh_data'     --dataset_dir  /home/ubisec/data/DPO_data     --template qwen     --finetuning_type lora  \
+#  --lora_rank 16     --lora_alpha 32     --lora_dropout 0.05     --lora_target all     --output_dir ./sft/dpo_qwen_all_1   \
+#  --use_dora True  --optim paged_adamw_8bit  --pref_loss orpo --pref_beta 0.1 \
+#  --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194   \
+#  --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16     --per_device_train_batch_size 1   \
+#  --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#  --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps    \
+#  --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0     --num_train_epochs 2.0     --val_size 0.05  \
+#  --ddp_timeout 180000000     --plot_loss     --bf16 
+
+# 第一版
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch  --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py --stage dpo  \
+#    --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B --dataset  'c_cpp_completion_dpo_train_data_20250609' \ 
+#    --dataset_dir  data/ --template qwen3  --finetuning_type lora  --lora_rank 32     --lora_alpha 32     --lora_dropout 0.05     --lora_target all   \
+#    --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter1 --use_dora False  --pref_loss orpo --pref_beta 0.1 \
+#    --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194    --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16  \
+#    --per_device_train_batch_size 1    --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#    --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps     --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0  \
+#    --num_train_epochs 2.0     --val_size 0.05   --ddp_timeout 180000000     --plot_loss     --bf16  --optim adamw_torch
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-orpo_model9 \
+#  --dataset  'c_cpp_completion_llamafactory-orpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 16  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo_adapter11 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.1  --overwrite_cache --overwrite_output_dir --cutoff_len 8194 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end    --learning_rate 5e-6 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim adamw_torch
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B-2 \
+#  --dataset  'c_cpp_completion_llamafactory-orpo_train_data_20250609_1600_random800' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 128  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-24 --use_dora False --use_rslora False \
+#  --pref_loss orpo --pref_beta 0.05  --overwrite_cache --overwrite_output_dir --cutoff_len 8192 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500 \
+#  --learning_rate 8e-5 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --ddp_timeout 180000000  --plot_loss  --bf16 --optim adamw_torch \
+#  > log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-24_20250903.log
+#  --val_size 0.05  --load_best_model_at_end --per_device_eval_batch_size 1  --eval_steps 500  --eval_strategy steps 
+#  --quantization_bit 4 --quantization_method bnb --double_quantization True
+
+
+
+
+
+#  --optim {adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,\
+#  adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,\
+#  paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,\
+#  galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}
\ No newline at end of file
diff --git a/examples/train_lora/qwen3_qlora_orpo26.yaml b/examples/train_lora/qwen3_qlora_orpo26.yaml
new file mode 100644
index 00000000..d79b658b
--- /dev/null
+++ b/examples/train_lora/qwen3_qlora_orpo26.yaml
@@ -0,0 +1,117 @@
+### model
+model_name_or_path: /home/ubisec/swh/models/Qwen3-Coder-30B-A3B-Instruct
+trust_remote_code: true
+
+### method
+stage: dpo
+do_train: true
+finetuning_type: lora
+lora_rank: 64
+lora_alpha: 32
+lora_dropout: 0.05
+lora_target: all
+pref_beta: 0.05
+pref_loss: orpo  # choices: [sigmoid (dpo), orpo, simpo]
+use_dora: false
+use_rslora: false
+enable_liger_kernel: true
+flash_attn: fa2
+optim: adamw_torch
+quantization_bit: 4
+quantization_method: bnb  # choices: [bnb, gptq, smoothq
+double_quantization: true
+
+### dataset
+dataset: c_cpp_completion_20250609-qa-orpo_1373_train_data_20250918
+template: qwen3
+cutoff_len: 8192 # 2048
+max_samples: 5000
+overwrite_cache: true
+preprocessing_num_workers: 16
+dataloader_num_workers: 4
+
+### output
+output_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-26
+logging_steps: 10
+save_steps: 500
+plot_loss: true
+overwrite_output_dir: true
+save_only_model: false
+report_to: none  # choices: [none, wandb, tensorboard, swanlab, mlflow]
+
+### train
+per_device_train_batch_size: 1
+gradient_accumulation_steps: 1 # 8
+learning_rate: 8.0e-5 # 5.0e-6
+loraplus_lr_ratio: 12.0
+num_train_epochs: 6.0
+lr_scheduler_type: cosine
+warmup_ratio: 0.1
+bf16: true
+ddp_timeout: 180000000
+resume_from_checkpoint: null
+
+### eval
+# eval_dataset: dpo_en_demo
+# val_size: 0.1
+# per_device_eval_batch_size: 1
+# eval_strategy: steps
+# eval_steps: 500
+
+
+
+#  DISABLE_VERSION_CHECK=1 CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch --config_file ./config/fsdp_config.yaml ./LLaMA-Factory/src/train.py   \
+#  --stage dpo     --do_train  --model_name_or_path /home/ubisec/codeqwen/merged_kit_qwen_model_3/  \
+#  --dataset 'dpo_zh_data'     --dataset_dir  /home/ubisec/data/DPO_data     --template qwen     --finetuning_type lora  \
+#  --lora_rank 16     --lora_alpha 32     --lora_dropout 0.05     --lora_target all     --output_dir ./sft/dpo_qwen_all_1   \
+#  --use_dora True  --optim paged_adamw_8bit  --pref_loss orpo --pref_beta 0.1 \
+#  --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194   \
+#  --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16     --per_device_train_batch_size 1   \
+#  --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#  --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps    \
+#  --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0     --num_train_epochs 2.0     --val_size 0.05  \
+#  --ddp_timeout 180000000     --plot_loss     --bf16 
+
+# 第一版
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch  --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py --stage dpo  \
+#    --do_train  --model_name_or_path /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B --dataset  'c_cpp_completion_dpo_train_data_20250609' \ 
+#    --dataset_dir  data/ --template qwen3  --finetuning_type lora  --lora_rank 32     --lora_alpha 32     --lora_dropout 0.05     --lora_target all   \
+#    --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-dpo_adapter1 --use_dora False  --pref_loss orpo --pref_beta 0.1 \
+#    --overwrite_cache     --overwrite_output_dir     --cutoff_len 8194    --enable_liger_kernel     --flash_attn fa2     --preprocessing_num_workers 16  \
+#    --per_device_train_batch_size 1    --per_device_eval_batch_size 1     --gradient_accumulation_steps 1     --lr_scheduler_type cosine     --logging_steps 10  \
+#    --warmup_ratio 0.1     --save_steps 1000     --eval_steps 500    --eval_strategy steps     --load_best_model_at_end     --learning_rate 5e-6     --loraplus_lr_ratio 12.0  \
+#    --num_train_epochs 2.0     --val_size 0.05   --ddp_timeout 180000000     --plot_loss     --bf16  --optim adamw_torch
+
+
+# DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,1 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+#  --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-orpo_model9 \
+#  --dataset  'c_cpp_completion_llamafactory-orpo_train_data_20250609_1600_random800_add_reason' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+#  --lora_rank 16  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+#  --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo_adapter11 --use_dora False \
+#  --pref_loss orpo --pref_beta 0.1  --overwrite_cache --overwrite_output_dir --cutoff_len 8194 --enable_liger_kernel  \
+#  --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \
+#  --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500  --eval_steps 500  --eval_strategy steps  \
+#  --load_best_model_at_end    --learning_rate 5e-6 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --val_size 0.05 --ddp_timeout 180000000  --plot_loss  --bf16 --optim adamw_torch
+
+
+DISABLE_VERSION_CHECK=1  CUDA_VISIBLE_DEVICES=0,4,6,7 accelerate launch --main_process_port 0 --config_file ./examples/train_lora/fsdp_config.yaml ./src/train.py \
+ --stage dpo --do_train  --model_name_or_path /home/ubisec/swh/models/Qwen3-Coder-30B-A3B-Instruct \
+ --dataset  'c_cpp_completion_20250609-qa-orpo_1373_train_data_20250918' --dataset_dir  data/ --template qwen3  --finetuning_type lora \
+ --lora_rank 64  --lora_alpha 32 --lora_dropout 0.05 --lora_target all  \
+ --output_dir /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-26 --use_dora False --use_rslora False \
+ --pref_loss orpo --pref_beta 0.05  --overwrite_cache --overwrite_output_dir --cutoff_len 8192 --enable_liger_kernel  \
+ --flash_attn fa2 --preprocessing_num_workers 16 --per_device_train_batch_size 1 \
+ --gradient_accumulation_steps 1 --lr_scheduler_type cosine  --logging_steps 10  --warmup_ratio 0.1  --save_steps 500 --max_samples 5000 \
+ --learning_rate 8e-5 --loraplus_lr_ratio 12.0 --num_train_epochs 6.0  --ddp_timeout 180000000  --plot_loss  --bf16 --optim adamw_torch \
+ > log/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-26_20250918.log
+#  --val_size 0.05  --load_best_model_at_end --per_device_eval_batch_size 1  --eval_steps 500  --eval_strategy steps 
+#  --quantization_bit 4 --quantization_method bnb --double_quantization True
+
+
+
+
+
+#  --optim {adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,\
+#  adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,\
+#  paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,\
+#  galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}
\ No newline at end of file
diff --git a/src/llamafactory/model/model_utils/quantization.py b/src/llamafactory/model/model_utils/quantization.py
index 8b227b7f..fce33d96 100644
--- a/src/llamafactory/model/model_utils/quantization.py
+++ b/src/llamafactory/model/model_utils/quantization.py
@@ -160,6 +160,7 @@ def configure_quantization(
                     bnb_4bit_quant_type=model_args.quantization_type,
                     bnb_4bit_quant_storage=model_args.compute_dtype,  # crucial for fsdp+qlora
                 )
+                print(f"init_kwargs['quantization_config']={init_kwargs['quantization_config']}")
             else:
                 raise ValueError("Bitsandbytes only accepts 4-bit or 8-bit quantization.")
 
diff --git a/src/llamafactory/train/dpo/trainer.py b/src/llamafactory/train/dpo/trainer.py
index da593d8d..fd8df7ab 100644
--- a/src/llamafactory/train/dpo/trainer.py
+++ b/src/llamafactory/train/dpo/trainer.py
@@ -184,6 +184,7 @@ class CustomDPOTrainer(DPOTrainer):
         reference_rejected_logps: Optional["torch.Tensor"],
     ) -> tuple["torch.Tensor", "torch.Tensor", "torch.Tensor"]:
         r"""Compute loss for preference learning."""
+        # print(f'self.finetuning_args.use_ref_model={self.finetuning_args.use_ref_model}, self.loss_type={self.loss_type}')
         if not self.finetuning_args.use_ref_model:
             if self.loss_type == "orpo":
                 losses = self.odds_ratio_loss(policy_chosen_logps, policy_rejected_logps)
-- 
2.34.1

