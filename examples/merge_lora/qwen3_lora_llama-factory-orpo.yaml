### Note: DO NOT use quantized model or quantization_bit when merging lora adapters

### model
model_name_or_path: /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B-2
adapter_name_or_path: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo-adapter-25
template: qwen3
trust_remote_code: true

### export
export_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-llamafactory-orpo_model25-2
export_size: 5
export_device: cpu  # choices: [cpu, auto]
export_legacy_format: false
