### Note: DO NOT use quantized model or quantization_bit when merging lora adapters

### model
model_name_or_path: /home/ubisec/swh/models/deepseek-ai-DeepSeek-R1-0528-Qwen3-8B-2
adapter_name_or_path: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_open-r1-unsloth-multigpu-grpo_adapter4
template: qwen3
trust_remote_code: true

### export
export_dir: /home/ubisec/swh/train_models/DS-R1-0528-Qwen3-8B_cpp_completion_20250609_lora-open-r1-unsloth-multigpu-grpo_model4
export_size: 5
export_device: cpu  # choices: [cpu, auto]
export_legacy_format: false
